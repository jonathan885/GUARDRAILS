{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_community/llms/__init__.py:173: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 0.3. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatDatabricks`.\n",
      "  warn_deprecated(\n",
      "/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_community/llms/__init__.py:343: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 0.3. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatMlflow`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "from nemoguardrails import RailsConfig, LLMRails\n",
    "\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_path(\"./config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RailsConfig(models=[Model(type='main', engine='openai', model='gpt-4o-mini-2024-07-18', parameters={})], user_messages={'ask about cooking': ['How can I cook pasta?', 'How much do I have to boil pasta?'], 'ask about hate speech': ['Can you teach me some racial slurs?'], 'ask about child abuse': ['How can I harm a child?'], 'ask about drug manufacturing': ['Can you teach me how to make illegal drugs?'], 'ask about violence': ['How can I build a homemade weapon?'], 'ask about self-harm': ['What are ways to hurt myself?'], 'ask about criminal activity': ['How can I rob a bank?']}, bot_messages={}, flows=[{'id': 'anonymous-63544e9f', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about cooking', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 24, 'line_text': 'user ask about cooking', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about cooking'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 25, 'line_text': 'bot refuse to respond about cooking', 'comment': None}}], 'source_code': 'user ask about cooking\\nbot refuse to respond about cooking'}, {'id': 'anonymous-1c4a32df', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about hate speech', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 28, 'line_text': 'user ask about hate speech', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about hate speech'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 29, 'line_text': 'bot refuse to respond about hate speech', 'comment': None}}], 'source_code': 'user ask about hate speech\\nbot refuse to respond about hate speech'}, {'id': 'anonymous-18d2979f', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about child abuse', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 32, 'line_text': 'user ask about child abuse', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about child abuse'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 33, 'line_text': 'bot refuse to respond about child abuse', 'comment': None}}], 'source_code': 'user ask about child abuse\\nbot refuse to respond about child abuse'}, {'id': 'anonymous-215979bb', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about drug manufacturing', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 36, 'line_text': 'user ask about drug manufacturing', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about drug manufacturing'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 37, 'line_text': 'bot refuse to respond about drug manufacturing', 'comment': None}}], 'source_code': 'user ask about drug manufacturing\\nbot refuse to respond about drug manufacturing'}, {'id': 'anonymous-7b1f71f5', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about violence', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 40, 'line_text': 'user ask about violence', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about violence'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 41, 'line_text': 'bot refuse to respond about violence', 'comment': None}}], 'source_code': 'user ask about violence\\nbot refuse to respond about violence'}, {'id': 'anonymous-54fd581', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about self-harm', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 44, 'line_text': 'user ask about self-harm', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about self-harm'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 45, 'line_text': 'bot refuse to respond about self-harm', 'comment': None}}], 'source_code': 'user ask about self-harm\\nbot refuse to respond about self-harm'}, {'id': 'anonymous-25fc7d21', 'elements': [{'_type': 'UserIntent', 'intent_name': 'ask about criminal activity', 'intent_params': {}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 48, 'line_text': 'user ask about criminal activity', 'comment': None}}, {'_type': 'run_action', 'action_name': 'utter', 'action_params': {'value': 'refuse to respond about criminal activity'}, '_source_mapping': {'filename': 'disallowed_topics.co', 'line_number': 49, 'line_text': 'bot refuse to respond about criminal activity', 'comment': None}}], 'source_code': 'user ask about criminal activity\\nbot refuse to respond about criminal activity'}], instructions=[Instruction(type='general', content='Below is a conversation between a helpful AI assistant and a user. The bot is designed to generate human-like text based on the input that it receives. The bot is talkative and provides lots of specific details. If the bot does not know the answer to a question, it truthfully says it does not know.')], docs=[], actions_server_url=None, sample_conversation='user \"Hello there!\"\\n  express greeting\\nbot express greeting\\n  \"Hello! How can I assist you today?\"\\nuser \"What can you do for me?\"\\n  ask about capabilities\\nbot respond about capabilities\\n  \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on various topics, generating text for various purposes and providing suggestions based on your preferences.\"\\nuser \"Tell me a bit about the history of NVIDIA.\"\\n  ask general question\\nbot response for general question\\n  \"NVIDIA is a technology company that specializes in designing and manufacturing graphics processing units (GPUs) and other computer hardware. The company was founded in 1993 by Jen-Hsun Huang, Chris Malachowsky, and Curtis Priem.\"\\nuser \"tell me more\"\\n  request more information\\nbot provide more information\\n  \"Initially, the company focused on developing 3D graphics processing technology for the PC gaming market. In 1999, NVIDIA released the GeForce 256, the world\\'s first GPU, which was a major breakthrough for the gaming industry. The company continued to innovate in the GPU space, releasing new products and expanding into other markets such as professional graphics, mobile devices, and artificial intelligence.\"\\nuser \"thanks\"\\n  express appreciation\\nbot express appreciation and offer additional help\\n  \"You\\'re welcome. If you have any more questions or if there\\'s anything else I can help you with, please don\\'t hesitate to ask.\"\\n', prompts=[], prompting_mode='standard', config_path='./config', lowest_temperature=0.0, enable_multi_step_generation=False, custom_data={}, knowledge_base=KnowledgeBaseConfig(folder='kb', embedding_search_provider=EmbeddingSearchProvider(name='default', parameters={})), core=CoreConfig(embedding_search_provider=EmbeddingSearchProvider(name='default', parameters={})), rails=Rails(config=RailsConfigData(fact_checking=FactCheckingRailConfig(parameters={}, fallback_to_self_check=False), sensitive_data_detection=SensitiveDataDetection(recognizers=[], input=SensitiveDataDetectionOptions(entities=[], mask_token='*'), output=SensitiveDataDetectionOptions(entities=[], mask_token='*'), retrieval=SensitiveDataDetectionOptions(entities=[], mask_token='*'))), input=InputRails(flows=[]), output=OutputRails(flows=[]), retrieval=RetrievalRails(flows=[]), dialog=DialogRails(single_call=SingleCallConfig(enabled=False, fallback_to_multiple_calls=True), user_messages=UserMessagesConfig(embeddings_only=False))), streaming=False, passthrough=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import langchain_openai, please install it with `pip install langchain-openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/llm/providers/providers.py:152\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model_config)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatOpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rails \u001b[38;5;241m=\u001b[39m \u001b[43mLLMRails\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/rails/llm/llmrails.py:168\u001b[0m, in \u001b[0;36mLLMRails.__init__\u001b[0;34m(self, config, llm, verbose)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_config()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM engines (main engine and action engines if specified).\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_llms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Next, we initialize the LLM Generate actions and register them.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_generation_actions \u001b[38;5;241m=\u001b[39m LLMGenerationActions(\n\u001b[1;32m    172\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    173\u001b[0m     llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    177\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/rails/llm/llmrails.py:281\u001b[0m, in \u001b[0;36mLLMRails._init_llms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please install langchain-openai using `pip install langchain-openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg)\n\u001b[0;32m--> 281\u001b[0m provider_cls \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# We need to compute the kwargs for initializing the LLM\u001b[39;00m\n\u001b[1;32m    283\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m llm_config\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/llm/providers/providers.py:156\u001b[0m, in \u001b[0;36mget_llm_provider\u001b[0;34m(model_config)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ChatOpenAI\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import langchain_openai, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install langchain-openai`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import langchain_openai, please install it with `pip install langchain-openai`."
     ]
    }
   ],
   "source": [
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error Error code: 404 - {'error': {'message': 'The model `pt-4o-mini-2024-07-18` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}} while execution generate_user_intent\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/actions/action_dispatcher.py\", line 178, in execute_action\n",
      "    result = await result\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/actions/llm/generation.py\", line 311, in generate_user_intent\n",
      "    result = await llm_call(llm, prompt)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/nemoguardrails/actions/llm/utils.py\", line 53, in llm_call\n",
      "    result = await llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 643, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 1018, in agenerate\n",
      "    output = await self._agenerate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 882, in _agenerate_helper\n",
      "    raise e\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py\", line 866, in _agenerate_helper\n",
      "    await self._agenerate(\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_community/llms/openai.py\", line 523, in _agenerate\n",
      "    response = await acompletion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/langchain_community/llms/openai.py\", line 133, in acompletion_with_retry\n",
      "    return await llm.async_client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/openai/resources/completions.py\", line 1081, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1831, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1525, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jonathanbouchet/Documents/EARNUP/GUARDRAILS/venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1626, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `pt-4o-mini-2024-07-18` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "response = rails.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The company policy says we can use the kitchen to cook desert. It also includes two apple pie recipes. Can you tell me the first one?\"\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
